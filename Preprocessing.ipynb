{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from loadData.ipynb\n",
      "importing Jupyter notebook from Util.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pdraw\n",
    "import collections\n",
    "from scipy import sparse\n",
    "import time\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "\n",
    "from loadData import raw_df, test_df\n",
    "from Util import getAllTypesofCategory, getAllTypesOfProperty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## impute missing value with most_frequent strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "contain_missing_value_columns = [\"item_brand_id\",\"item_city_id\",\"item_sales_level\",\"user_gender_id\",\"user_age_level\",\n",
    "                                \"user_occupation_id\",\"user_star_level\",\"shop_review_positive_rate\",\n",
    "                                \"shop_score_service\",\"shop_score_delivery\",\"shop_score_description\"]\n",
    "other_missing_value_columns = [\"predict_category_property\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputer = Imputer(missing_values=-1 , strategy='most_frequent', axis=0)\n",
    "raw_df[contain_missing_value_columns] = data_imputer.fit_transform(raw_df[contain_missing_value_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processing  predict_category_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predict_category_property_feature(df):\n",
    "    def process_func(item):\n",
    "        result = {}\n",
    "        for i in item.split(';'):\n",
    "            if ':' in i:\n",
    "                items = i.split(':')\n",
    "                category = int(items[0])\n",
    "                properties = items[1]\n",
    "                if ',' in properties:\n",
    "                    result[category] = map(int,items[1].split(','))\n",
    "                else:\n",
    "                    result[category] = [int(items[1])]\n",
    "        return result\n",
    "    def process_category(item):\n",
    "        return list(process_func(item).keys())\n",
    "    def process_property(item):\n",
    "        _ = process_func(item).values()\n",
    "        return set(itertools.chain(*_))\n",
    "    df['predict_categories'] = df['predict_category_property'].apply(lambda item: process_category(item))\n",
    "    df['predict_properties'] = df['predict_category_property'].apply(lambda item: process_property(item))\n",
    "generate_predict_category_property_feature(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # impute empty missing value in index 160943  205272  214168 314685\n",
    "# raw_df['predict_categories'][160943]= ['7908382889764677758']\n",
    "# raw_df['predict_categories'][205272] = ['7908382889764677758']\n",
    "# raw_df['predict_categories'][214168] = ['7908382889764677758']\n",
    "# raw_df['predict_categories'][314685] = ['7908382889764677758']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = raw_df['predict_categories'].values\n",
    "all_categories = list(set(itertools.chain(*tmp)))\n",
    "category_label_encode = LabelEncoder()\n",
    "all_categories_labels = category_label_encode.fit_transform(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df['predict_categories'] = raw_df['predict_categories'].apply(lambda item: category_label_encode.transform(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_label_oh_enc = OneHotEncoder()\n",
    "category_label_oh_enc.fit(all_categories_labels.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_categories_df = raw_df['predict_categories'].apply(lambda item: np.sum(category_label_oh_enc.transform(item.reshape(-1,1)),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_npz('../processed_data/predict_categories.npz',  csr_matrix(np.concatenate(predict_categories_df.values).reshape(len(predict_categories_df),-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processing the object column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split category_list to multi features\n",
    "# def extract_item_category_list_func(item, num):\n",
    "#     items = item.split(';')\n",
    "#     if num >=2:\n",
    "#         if len(items) > 2:\n",
    "#             return items[num]\n",
    "#         else:\n",
    "#             return 0\n",
    "#     else:\n",
    "#         return items[num]\n",
    "# def generate_item_category_features():\n",
    "#     raw_df['item_one_level_category'] = raw_df['item_category_list'].apply(lambda item: extract_item_category_list_func(item, 0))\n",
    "#     raw_df['item_second_level_category'] = raw_df['item_category_list'].apply(lambda item: extract_item_category_list_func(item, 1))\n",
    "#     raw_df['item_third_level_category'] = raw_df['item_category_list'].apply(lambda item: extract_item_category_list_func(item, 2))\n",
    "# #     raw_df.drop('item_category_list', axis=1)\n",
    "# generate_item_category_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df[['item_one_level_category', 'item_second_level_category', 'item_third_level_category']].to_csv('../processed_data/three_level_category.csv', sep=' ',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_item_property_list_func = lambda item: list(item.split(';'))\n",
    "# raw_df['item_property_list_array'] = raw_df['item_property_list'].apply(lambda item: extract_item_property_list_func(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('../processed_data/item_property_list_array.txt', raw_df['item_property_list_array'].reshape(len(raw_df['item_property_list_array']), -1), fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate new raw_df called _raw_df after filling missing value and handle category_id and property _id, drop useless column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df = raw_df.drop(['item_category_list','item_property_list'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need_onehot_columns = ['item_brand_id','item_city_id','user_gender_id','item_one_level_category', 'item_second_level_category']\n",
    "# special_onehot_columns = ['item_property_list_array', 'item_third_level_category']\n",
    "# other_columns = ['context_timestamp','predict_category_property','is_trade']\n",
    "# need_scale_columns = ['item_price_level','item_sales_level','item_collected_level','item_pv_level',\n",
    "#                      'user_age_level','user_occupation_id','user_star_level','context_page_id',\n",
    "#                      'shop_review_num_level','shop_review_positive_rate','shop_star_level','shop_score_service',\n",
    "#                     'shop_score_description', 'day', 'hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #transform to label type\n",
    "# for i in ['item_brand_id','item_city_id','user_gender_id']:\n",
    "#     raw_df[i] = raw_df[i].apply(lambda item : str(item)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need_onehot_df = pd.get_dummies(raw_df[need_onehot_columns], prefix=need_onehot_columns)\n",
    "# save_npz('../processed_data/need_onehot_columns.npz', csr_matrix(need_onehot_df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### item_third_level_category process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third_level_items = raw_df['item_third_level_category'].unique()\n",
    "\n",
    "# lb = LabelEncoder()\n",
    "# _tmp = lb.fit_transform(third_level_items)\n",
    "# result = lb.transform(raw_df['item_third_level_category'].values)\n",
    "\n",
    "# ohenc = OneHotEncoder()\n",
    "# ohenc.fit(_tmp.reshape(-1,1))\n",
    "# result = ohenc.transform(result.reshape(-1,1))\n",
    "\n",
    "# tmp_df = pd.DataFrame(data=result.toarray(), columns=['item_third_level_None', 'item_third_level_8868887661186419229', 'item_third_level_6233669177166538628'])\n",
    "\n",
    "# tmp_df.to_csv('../processed_data/item_third_level_one_hot.csv', sep=' ',float_format='%d',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  handle property list , label encode first and then onehot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays = list(raw_df['item_property_list_array'])\n",
    "# count = collections.Counter(list(itertools.chain(*arrays)))\n",
    "# most_common_property_id_list = list(list(zip(*count.most_common(1499)))[0])\n",
    "# most_common_property_id_list.append('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder()\n",
    "# le.fit(most_common_property_id_list)\n",
    "# most_common_property_id_num_list = le.transform(most_common_property_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label property id in item_property_list_array\n",
    "# for i in range(raw_df.shape[0]):\n",
    "#     for index, _id in enumerate(raw_df['item_property_list_array'][i]):\n",
    "#         if _id not in most_common_property_id_list:\n",
    "#             raw_df['item_property_list_array'][i][index] = 'o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df['item_property_list_array'] = raw_df['item_property_list_array'].apply(lambda item:le.transform(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = OneHotEncoder()\n",
    "# enc.fit(most_common_property_id_num_list.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _tmp_df = raw_df['item_property_list_array'].apply(lambda item: np.sum(enc.transform(item.reshape(-1,1)),axis=0).reshape(1,-1)[0])\n",
    "# save_npz('../processed_data/item_property.npz', csr_matrix(np.concatenate(_tmp_df.values).reshape(len(_tmp_df),-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scaling data in need_scale_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # min-max normalization\n",
    "# _tmpdf = raw_df[need_scale_columns]\n",
    "# # normalized_df = (_tmpdf - _tmpdf.min())/(_tmpdf.max() - _tmpdf.min())\n",
    "\n",
    "# # mean normalization\n",
    "# normalized_df = (_tmpdf - _tmpdf.mean())/_tmpdf.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_df.to_csv('../processed_data/scaled.csv', sep=' ',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
